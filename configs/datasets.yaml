# Dataset-specific configurations
# This file handles data loading, preprocessing, and partitioning

# Global data settings
data_split:
  train_subset_size: 10000
  test_subset_size: 2000
  validation_split: 0.2

# Text processing
text_column: "text"
label_column: "label"
label_mapping:
  0: "negative"
  1: "positive"

# Caching
cache_dir: "data/cache"
use_cache: true

# Available datasets
datasets:
  imdb:
    name: "imdb"
    source: "huggingface"
    dataset_id: "imdb"
    version: "1.0.0"
    cache_dir: ${cache_dir}/imdb
  yelp_polarity:
    name: "yelp_polarity"
    source: "huggingface"
    dataset_id: "yelp_polarity"
    version: "1.0.0"
    cache_dir: ${cache_dir}/yelp_polarity
    
  amazon_polarity:
    name: "amazon_polarity"
    source: "huggingface"
    dataset_id: "amazon_polarity"
    version: "1.0.0"
    cache_dir: ${cache_dir}/amazon_polarity

# Data preprocessing pipeline
preprocessing:
  # Text cleaning
  text_cleaning:
    remove_html_tags: true
    remove_urls: true
    remove_mentions: false
    remove_hashtags: false
    normalize_whitespace: true
    remove_extra_spaces: true
    
  # Text normalization
  text_normalization:
    lowercase: true
    strip_accents: "unicode"
    remove_punctuation: false
    normalize_unicode: true
    
  # Tokenization (for transformer models)
  tokenization:
    max_length: 512
    padding: "max_length"
    truncation: true
    return_tensors: "pt"
    add_special_tokens: true
    
  # Vectorization (for baseline models)
  vectorization:
    max_features: 10000
    ngram_range: [1, 2]
    min_df: 2
    max_df: 0.95
    stop_words: "english"
    lowercase: true
    strip_accents: "unicode"

# Data loading settings
data_loading:
  # Batch processing
  batch_size: 32
  shuffle: true
  num_workers: 0  # Use main process for MPS compatibility
  pin_memory: false  # Not needed for MPS
  
  # Memory management
  lazy_loading: true
  cache_processed_data: true
  max_cache_size: "2GB"
  
  # Data augmentation (disabled for overfitting experiments)
  augmentation:
    enabled: false
    techniques: []
    
# Data validation
data_validation:
  # Quality checks
  check_duplicates: true
  check_empty_texts: true
  check_label_distribution: true
  min_samples_per_class: 100
  
  # Statistics to compute
  compute_statistics:
    - "text_length_distribution"
    - "label_distribution"
    - "vocabulary_size"
    - "class_balance"